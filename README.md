# MCP LLM Bridge

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€O1ãƒ¢ãƒ‡ãƒ«ã¨GPT-4ã‚’çµ„ã¿åˆã‚ã›ã¦é«˜åº¦ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿç¾ã™ã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

## ä¸»ãªæ©Ÿèƒ½

### 1. æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹
- O1ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è³ªå•ã®åˆ†æã¨å®Ÿè¡Œè¨ˆç”»ã®ç«‹æ¡ˆ
- GPT-4ã«ã‚ˆã‚‹å…·ä½“çš„ãªãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ
- æ®µéšçš„ãªæƒ…å ±åé›†ã¨çµæœã®åˆ†æ

### 2. åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«
- **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®å¯¾è©±** (human_interaction)
  - è‡ªç„¶ãªä¼šè©±å½¢å¼ã§ã®è³ªå•
  - å…·ä½“çš„ãªæƒ…å ±ã®åé›†
  - æ„å›³ã®æ˜ç¢ºåŒ–

- **Googleæ¤œç´¢** (google_search)
  - ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰ã®æƒ…å ±åé›†
  - æœ€å¤§10ä»¶ã®é–¢é€£çµæœå–å¾—
  - å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹æ¤œç´¢

- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª** (database_query)
  - SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
  - å•†å“æƒ…å ±ã‚„ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã®å–å¾—
  - ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã¨é›†è¨ˆ

### 3. ä½¿ç”¨ä¾‹

```bash
Enter your prompt (or 'quit' to exit): AAã®æ›²åãªã‚“ã ã£ãŸã£ã‘ãª

ğŸ¤– AAã¨ã¯ã©ã®ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã‚„ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æŒ‡ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ
ğŸ‘¤ FF11ã®ã‚¢ãƒ¼ã‚¯ã‚¨ãƒ³ã‚¸ã‚§ãƒ«ã¤ã¾ã‚ŠAAã¨æˆ¦ã†ã¨ãã®æ›²ã ã‚ˆ

ã€å®Ÿè¡Œçµæœã€‘
FF11ã®ã‚¢ãƒ¼ã‚¯ã‚¨ãƒ³ã‚¸ã‚§ãƒ«æˆ¦ã§æµã‚Œã‚‹æ›²ã¯ã€ŒFighters of the Crystalã€ã§ã™ã€‚
ä½œæ›²è€…ã¯æ°´ç”°ç›´å¿—æ°ã§ã™ã€‚
```

ã“ã®ã‚ˆã†ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ›–æ˜§ãªè³ªå•ã«å¯¾ã—ã¦ï¼š
1. ã¾ãšè³ªå•ã§å¯¾è©±çš„ã«æ„å›³ã‚’æ˜ç¢ºåŒ–
2. å¿…è¦ã«å¿œã˜ã¦Googleæ¤œç´¢ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢ã‚’å®Ÿè¡Œ
3. åé›†ã—ãŸæƒ…å ±ã‚’åˆ†æã—ã¦æœ€çµ‚çš„ãªå›ç­”ã‚’æä¾›

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# Install
curl -LsSf https://astral.sh/uv/install.sh | sh
git clone https://github.com/bartolli/mcp-llm-bridge.git
cd mcp-llm-bridge
uv venv
source .venv/bin/activate  # Linux/Mac
# ã¾ãŸã¯
.\.venv\Scripts\Activate.ps1  # Windows
uv pip install -e .

# Create test database
python -m mcp_llm_bridge.create_test_db
```

## è¨­å®š

### OpenAI APIè¨­å®š

`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼š

```bash
OPENAI_API_KEY=your_key
OPENAI_MODEL=gpt-4o  # Function Callingå¯¾å¿œãƒ¢ãƒ‡ãƒ«
```

### Additional Endpoint Support

The bridge also works with any endpoint implementing the OpenAI API specification:

#### Ollama

```python
llm_config=LLMConfig(
    api_key="not-needed",
    model="mistral-nemo:12b-instruct-2407-q8_0",
    base_url="http://localhost:11434/v1"
)
```

Note: After testing various models, including `llama3.2:3b-instruct-fp16`, I found that `mistral-nemo:12b-instruct-2407-q8_0` handles complex queries more effectively.

#### LM Studio

```python
llm_config=LLMConfig(
    api_key="not-needed",
    model="local-model",
    base_url="http://localhost:1234/v1"
)
```

I didn't test this, but it should work.

### å®Ÿè¡Œ

```bash
python -m mcp_llm_bridge.main
```

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

[MIT](LICENSE.md)

## è²¢çŒ®

PRs welcome.

cd mcp-llm-bridge ; .venv/Scripts/activate ; python -m mcp_llm_bridge.main


cd mcp-llm-bridge
.\.venv\Scripts\Activate.ps1
python -m mcp_llm_bridge.main